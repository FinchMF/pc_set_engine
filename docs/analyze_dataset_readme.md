# Dataset Analysis and Validation Tool

## Overview

The `analyze_dataset.py` module provides powerful tools for analyzing, validating, and fixing datasets generated by the PC Rules Engine. This tool is particularly useful for verifying simulation success rates, correcting statistical inconsistencies in datasets, and extracting meaningful insights from simulation results.

## Key Features

- **Validation of Simulation Success**: Intelligently determines if a simulation was truly successful by examining key indicators 
- **Fix Dataset Statistics**: Corrects success/failure counts in dataset metadata
- **Batch Processing**: Process multiple datasets in one command
- **Distribution Analysis**: Analyze parameter and outcome distributions across simulations
- **Automatic Reporting**: Generate summary statistics and CSV reports for further analysis

## Installation

No additional installation is required beyond the core PC Rules Engine dependencies. The tool uses:

- Python 3.6+
- pandas
- PyYAML

## Usage

### Command Line Interface

The module can be invoked directly from the command line with several subcommands:

#### Fix a Single Dataset File

```bash
python analyze_dataset.py fix dataset_file.json [--output OUTPUT_FILE]
```

**Arguments**:
- `dataset_file.json`: Path to the dataset file to fix
- `--output/-o` (optional): Path to save the fixed dataset (if omitted, overwrites original)

**Example**:
```bash
python analyze_dataset.py fix large_training_set/large_diverse_dataset.json --output fixed_dataset.json
```

#### Fix All Datasets in a Directory

```bash
python analyze_dataset.py fix-all directory [--recursive]
```

**Arguments**:
- `directory`: Directory containing dataset files
- `--recursive/-r` (optional): Process subdirectories as well

**Example**:
```bash
python analyze_dataset.py fix-all large_training_set --recursive
```

#### Analyze Parameter and Outcome Distributions

```bash
python analyze_dataset.py analyze dataset_file.json [--output-dir OUTPUT_DIR]
```

**Arguments**:
- `dataset_file.json`: Path to the dataset file to analyze
- `--output-dir/-o` (optional): Directory to save analysis outputs (if omitted, uses current directory)

**Example**:
```bash
python analyze_dataset.py analyze large_training_set/large_diverse_dataset.json --output-dir analysis_results
```

### Programmatic Usage

You can also use the module functions directly in your Python scripts:

```python
from analyze_dataset import fix_simulation_statistics, analyze_dataset_distributions

# Fix statistics in a dataset
stats = fix_simulation_statistics('path/to/dataset.json', 'path/to/output.json')
print(f"Fixed {stats['changes']['flipped_to_success']} simulations to successful")

# Analyze a dataset
analysis = analyze_dataset_distributions('path/to/dataset.json', 'output_directory')
print(f"Success rate: {analysis['success_rate']:.2%}")
```

## How It Works

### Validating Simulation Success

The tool uses a sophisticated validation algorithm that looks at multiple indicators to determine if a simulation was actually successful:

1. Checks if pitch classes were generated
2. Verifies if MIDI files were created
3. Looks for error messages
4. Examines execution time

This allows for more accurate success statistics than what might be recorded during the initial simulation.

### Fixing Dataset Statistics

When fixing dataset statistics, the tool:

1. Loads the dataset JSON file
2. Re-validates each simulation's success status
3. Updates success flags for each simulation
4. Recalculates overall success/failure counts in the metadata
5. Saves the corrected dataset

### Analyzing Distributions

The analysis functionality:

1. Extracts parameters, rhythm settings, and statistics from each simulation
2. Converts data to a pandas DataFrame for analysis
3. Generates basic statistical summaries
4. Computes success rates by group
5. Saves results as CSV files and a JSON summary

## Output Files

### Fix Operation

- Original dataset with corrected success flags and metadata
- Or a new file if `--output` is specified

### Analysis Operation

- `dataset_stats.csv`: Basic statistical measures for all numerical parameters
- `group_success_rates.csv`: Success rates broken down by simulation group
- `processed_dataset.csv`: Flattened dataset with all parameters and outcomes
- `analysis_summary.json`: Summary of analysis results and metadata

## Best Practices

1. **Always fix statistics** before analyzing a dataset
2. Use `fix-all` with `--recursive` for batch processing large dataset collections
3. Store analysis outputs in dedicated directories with `--output-dir`
4. Review the analysis_summary.json for a quick overview of dataset characteristics

## Troubleshooting

### Common Issues

- **JSON parsing errors**: Verify the dataset file is valid JSON
- **Missing fields**: Some simulations might have different structures; the tool tries to handle this gracefully
- **Memory issues**: For very large datasets, consider analyzing groups separately

### Solutions

- Run with smaller batches of data if memory is an issue
- Ensure the dataset was properly generated before analysis
- Check logs for specific error messages that might indicate structural issues

## Advanced Usage

### Custom Success Validation

You can modify the `validate_simulation_success` function to use different criteria for determining simulation success based on your specific use case. For example, you might have additional metrics that indicate success.

### Creating Custom Analysis Reports

The tool outputs processed data as CSVs, which can be easily imported into other data analysis tools like:

- Excel or Google Sheets for further analysis
- Matplotlib or Seaborn for custom visualizations
- R for advanced statistical analysis

## Conclusion

The analyze_dataset module provides essential tools for ensuring the quality and correctness of your simulation datasets. By validating and fixing success statistics and providing detailed analytical capabilities, it helps ensure your research and development with the PC Rules Engine is based on accurate data.
